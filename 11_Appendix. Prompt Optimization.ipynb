{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72fae4e-f7de-42b7-91ee-bdd0a57ae46c",
   "metadata": {
    "id": "d72fae4e-f7de-42b7-91ee-bdd0a57ae46c"
   },
   "source": [
    "# **Appendix: LangGraph - A Framework for Prompt Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec4359",
   "metadata": {},
   "source": [
    "This chapter, unlike the previous ones, delves into an **advanced version of prompt engineering**, introducing methods for **prompt optimization**. There are various ways to optimize prompts, and among them, we will demonstrate how to use **LangGraph with Solar** to effectively enhance and refine prompts.\n",
    "\n",
    "The reason for choosing prompt engineering using LangGraph among many advanced techniques is that LangGraph's features enable the integration of a **\"human feedback\"** process during the prompt extraction stage.\n",
    "\n",
    "> LangGraph is a visual framework for structuring and optimizing prompts.  \n",
    "> It maps linguistic elements to functional goals, clarifying how prompt components influence outputs.  \n",
    "> By organizing prompts into nodes (language elements), edges (relationships), and goals (desired outcomes), LangGraph connects linguistic intuition with technical implementation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610f1b2",
   "metadata": {},
   "source": [
    "**What You'll Learn in This Appendix**\n",
    "\n",
    "- [The core structure and components of LangGraph](#1)\n",
    "\n",
    "- [How to visualize prompt interactions and their outcomes](#2)\n",
    "\n",
    "- [A practical example of prompt optimization](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c947c3",
   "metadata": {
    "id": "d9c947c3"
   },
   "source": [
    "**Set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a324088",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langgraph langchain_core langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f53f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# Retrieve the UPSTAGE_API_KEY variable from the IPython store\n",
    "%store -r UPSTAGE_API_KEY\n",
    "\n",
    "try:\n",
    "    if UPSTAGE_API_KEY:\n",
    "        print(\"Success!\")\n",
    "except NameError as ne:\n",
    "    print(f\"Since, {ne}\")\n",
    "    print(\"Please, insert your API key.\")\n",
    "    UPSTAGE_API_KEY = input(\"UPSTAGE_API_KEY =\")\n",
    "\n",
    "# Set your API key: \n",
    "# UPSTAGE_API_KEY = \" \" â†- Insert your API key here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855829b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "def get_llm(model: str =\"solar-pro\", temperature: float=0.0, **kwargs: any)-> ChatOpenAI:\n",
    "    return ChatOpenAI(\n",
    "        api_key=os.environ[\"UPSTAGE_API_KEY\"],\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "parser = RegexParser(\n",
    "    regex=r\"revised prompt:\\s*(.+)\",\n",
    "    output_keys=[\"revised_prompt\"]\n",
    ")\n",
    "\n",
    "solar = get_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4ecaa",
   "metadata": {},
   "source": [
    "**Set up the State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da182839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "import operator  \n",
    "\n",
    "# Set up the GraphState\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    A TypedDict class representing the state of the prompt optimization graph.\n",
    "\n",
    "    Attributes:\n",
    "        prompt (Annotated[list, operator.add]): List containing the prompts being optimized\n",
    "        ai_feedback (Annotated[list, operator.add]): List containing AI-generated feedback on prompts\n",
    "        human_feedback (Annotated[list, operator.add]): List containing human feedback on prompts\n",
    "    \"\"\"\n",
    "\n",
    "    prompt: Annotated[list, operator.add]\n",
    "    ai_feedback: Annotated[list, operator.add]\n",
    "    human_feedback: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83f565",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ae910",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## **1. Prompt Optimization with LangGraph: 5-Step Process with Solar** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d8c75",
   "metadata": {},
   "source": [
    "[Step 1: Analyze the Prompt Given by User](#step1)  \n",
    "\n",
    "[Step 2: Human Feedback](#step2) \n",
    "\n",
    "[Step 3: Test the Prompt](#step3)\n",
    "\n",
    "[Step 4: Optimize the Prompt](#step4)\n",
    "\n",
    "[Step 5: Evaluate the Prompt](#step5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082af49d",
   "metadata": {
    "id": "082af49d"
   },
   "source": [
    "### **1.1 Define the Nodes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "- **Step 1: Analyze the Prompt Given by User**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301856d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1st node: analyze_prompt\n",
    "def analyze_prompt(state: GraphState, llm: ChatOpenAI=solar) -> GraphState:\n",
    "    \"\"\"\n",
    "    Analyzes the given prompt and revise it for improvement.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state contains the prompt to analyze\n",
    "        llm (ChatOpenAI): Language model( Solar with temperature: 0.0 ) used to generate feedback and improvements\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Updated state with AI feedback and revised prompt\n",
    "    \"\"\"\n",
    "    latest_prompt = state[\"prompt\"][0]\n",
    "\n",
    "    print(\"[ Here is the user's prompt ]\")\n",
    "    print(latest_prompt)\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "    Your task is to analyze user's prompt. \n",
    "\n",
    "    1. Extract the user's intent. And write down a single word focused on 'action ascription'.\n",
    "    2. Check your output is aligned with the user's intent.   \n",
    "    3. Suggest me some improvements for the prompt. \n",
    "    4. Revise my prompt to ensure it includes two focal elements: examples and ample context within the prompt.\n",
    "    5. Your output should be within 4 sentences. Format: \n",
    "        (1) user's intent:\n",
    "        (2) some improvement:\n",
    "        (3) revised prompt: *don't answer to the user's prompt.\n",
    "        \n",
    "                                          \n",
    "    --------> \n",
    "    User's prompt: \n",
    "    {prompt}\n",
    "    --------> \n",
    "    \"\"\")\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    output = chain.invoke({\"prompt\": latest_prompt})\n",
    "    response = f\"Here is the feedback generated by AI: \\n{output}\"\n",
    "\n",
    "    parsed_response = parser.parse(output)\n",
    "    revised_prompt = parsed_response[\"revised_prompt\"]\n",
    "\n",
    "    return {\"prompt\": [revised_prompt],\n",
    "            \"ai_feedback\": [response]}\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87666192",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "- **Step 2: Human Feedback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bd2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2nd node: human\n",
    "def human_feedback(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Collects feedback from the user.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Update state with human feedback\n",
    "    \"\"\"\n",
    "    print(\"[ Here is the proposed prompt ] \\n\", state['prompt'][-1])\n",
    "    user_input = input(\"(Press 'q' or 'quit' to quit)\")\n",
    "\n",
    "    return {\"human_feedback\": [user_input]}\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b1087",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "- **Step 3: Test the Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0a921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3rd node: test_prompt\n",
    "def test_optimized_prompt(state: GraphState, llm: ChatOpenAI=get_llm(temperature=0.7)) -> GraphState:\n",
    "    \"\"\"\n",
    "    Tests both previous and current prompts, comparing their responses.\n",
    "    \n",
    "    Args:\n",
    "        state (GraphState): Current state containing both prompts\n",
    "        llm (ChatOpenAI): Language model( Solar with temperature: 0.7 ) used to generate feedback\n",
    "        \n",
    "    Returns:\n",
    "        GraphState: Updated state with comparison of responses\n",
    "    \"\"\"\n",
    "    previous_prompt = state[\"prompt\"][-2]  # Get previous prompt\n",
    "    current_prompt = state[\"prompt\"][-1]  # Get latest prompt\n",
    "    \n",
    "    # Get responses for both prompts\n",
    "    previous_response = llm.invoke(previous_prompt)\n",
    "    revised_response = llm.invoke(current_prompt)\n",
    "    \n",
    "    # Compare the responses\n",
    "    comparison_prompt = f\"\"\"\n",
    "    Compare these two responses:\n",
    "    \n",
    "    PREVIOUS PROMPT: {previous_prompt}\n",
    "    PREVIOUS RESPONSE: {previous_response.content}\n",
    "    \n",
    "    REVISED PROMPT: {current_prompt}\n",
    "    REVISED RESPONSE: {revised_response.content}\n",
    "    \n",
    "    Please analyze:\n",
    "    1. Key differences in responses. \n",
    "    2. Summarize the differences within 1 sentence.  \n",
    "    3. tell me which one is better: Previous or Revised?  \n",
    "    \"\"\"\n",
    "\n",
    "    analysis = llm.invoke(comparison_prompt)\n",
    "    \n",
    "    return {\"ai_feedback\": [\n",
    "        f\"Previous Prompt Response:\\n{previous_response.content}\\n\\n\"\n",
    "        f\"Revised Prompt Response:\\n{revised_response.content}\\n\\n\"\n",
    "        f\"Comparative Analysis:\\n{analysis.content}\"\n",
    "    ]}\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389c700",
   "metadata": {},
   "source": [
    "<a id=\"step4\"></a>\n",
    "- **Step 4: Optimize the Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be7a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4th node: optimize_prompt\n",
    "def optimize_prompt(state: GraphState, llm: ChatOpenAI=solar) -> GraphState:\n",
    "    \"\"\"\n",
    "    Optimizes the prompt based on your feedback and the user's feedback. \n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state contains the prompt, AI feedback(your feedback), and the user's feedback \n",
    "        llm (ChatOpenAI): Language model( Solar with temperature: 0.0 ) used to optimize prompt based on feedback\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Updated state with optimized prompt\n",
    "    \"\"\"\n",
    "    latest_prompt = state[\"prompt\"][-1]\n",
    "    latest_ai_feedback = state[\"ai_feedback\"][-1]\n",
    "    latest_human_feedback = state[\"human_feedback\"][-1]\n",
    "\n",
    "    if latest_human_feedback == \"q\" or latest_human_feedback == \"quit\":\n",
    "        latest_human_feedback = \"\"\n",
    "        return {\"prompt\": [latest_prompt]}\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Your task is to optimize the user's prompt. Follow these instructions: \n",
    "\n",
    "    Here is the prompt before improvement:\n",
    "    {prompt}\n",
    "\n",
    "    Here is previous feedback generated by AI:\n",
    "    {ai_feedback}\n",
    "\n",
    "    Here is Human's follow-up feedback:\n",
    "    {human_feedback}\n",
    "\n",
    "    Write down the improved prompt. Only present the revised prompt without any additional comments. \n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"prompt\": latest_prompt,\n",
    "            \"ai_feedback\": latest_ai_feedback,\n",
    "            \"human_feedback\": latest_human_feedback,\n",
    "        }\n",
    "    )\n",
    "    return {\"prompt\": [response]}\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08418d",
   "metadata": {},
   "source": [
    "<a id=\"step5\"></a>\n",
    "- **Step 5: Evaluate the Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb961ee",
   "metadata": {
    "id": "3fb961ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5th node: evaluate_prompt\n",
    "def evaluate_prompt(state: GraphState, llm: ChatOpenAI=solar) -> GraphState:\n",
    "    \"\"\"\n",
    "    Evaluates the optimized prompt by comparing it to the previous prompt.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state contains the previous prompt and the optimized prompt\n",
    "        llm (ChatOpenAI): Language model( Solar with temperature: 0.0 ) used to evaluate the optimized prompt\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Updated state with evaluation feedback\n",
    "    \"\"\"\n",
    "    before_optimization_prompt = state[\"prompt\"][-2]\n",
    "    improved_prompt = state[\"prompt\"][-1]\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "    Now, let's evaluate the prompt. Follow these instructions: \n",
    "    - 1. Comparision : read two prompts carefully and think about the difference between them.  \n",
    "    previous prompt: {before_optimization_prompt}\n",
    "    revised prompt: {improved_prompt}\n",
    "\n",
    "    - 2. Scoring: Give a score between 0 and 1 for 4 criteria. Show your the total score at the end. \n",
    "    If yes add 1, else add 0.   \n",
    "      - 2.1) Is the revised prompt aligned with the user's intent? (yes or no)\n",
    "      - 2.2) Is the revised prompt able to generate a better output than the previous prompt? (yes or no)\n",
    "      - 2.3) Is the revised prompt well-structured? (yes or no)\n",
    "      - 2.4) Is the revised prompt of flexible length? (yes or no) \n",
    "    Sum up your score for each criterion: [ ]\n",
    "       \n",
    "    - 3. Writedown the justification for your score within 2 sentences. \n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"before_optimization_prompt\": before_optimization_prompt,\n",
    "            \"improved_prompt\": improved_prompt,\n",
    "        }\n",
    "    )\n",
    "    return {\"ai_feedback\": [response]}\n",
    "\n",
    "# An additional path: CONTINUE \n",
    "def should_continue(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether to continue the optimization loop based on the user's feedback.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state containing the user's feedback\n",
    "\n",
    "    Returns:\n",
    "        str: \"FINISH\" if the user wants to quit, \"CONTINUE\" otherwise\n",
    "    \"\"\"\n",
    "    latest_human_feedback = state[\"human_feedback\"][-1].strip()\n",
    "    if latest_human_feedback == \"q\" or latest_human_feedback == \"quit\":\n",
    "        return \"FINISH\"\n",
    "    else:\n",
    "        return \"CONTINUE\"\n",
    "    \n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb3df2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1379d",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## **2. LangGraph Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232214f",
   "metadata": {},
   "source": [
    "### **2.1 Set up the Graph**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c852891",
   "metadata": {
    "id": "6c852891"
   },
   "source": [
    "This code sets up a LangGraph workflow for prompt optimization with the following components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06d485",
   "metadata": {},
   "source": [
    "**1. Memory Management**:\n",
    "\n",
    "   - Uses **`MemorySaver`** for maintaining state across workflow steps\n",
    "\n",
    "   - Creates a **`StateGraph`** instance for managing prompt optimization states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b16fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "memory = MemorySaver()\n",
    "workflow = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098f38b",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "**2. Node Configuration**:\n",
    "\n",
    "   - `analyze_prompt`: Analyzes the initial prompt\n",
    "\n",
    "   - `human`: Handles human feedback loop\n",
    "\n",
    "   - `optimize_prompt`: Performs prompt optimization\n",
    "\n",
    "   - `evaluate_prompt`: Evaluates optimization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07268d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10eedefc0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"analyze_prompt\", analyze_prompt)\n",
    "workflow.add_node(\"human\", human_feedback)\n",
    "workflow.add_node(\"test_prompt\", test_optimized_prompt)\n",
    "workflow.add_node(\"optimize_prompt\", optimize_prompt)\n",
    "workflow.add_node(\"evaluate_prompt\", evaluate_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6c597",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "**3. Edge Configuration**:\n",
    "\n",
    "   - **Linear flow** from analyze_prompt to human\n",
    "\n",
    "   - **Conditional branching** from human based on should_continue function\n",
    "\n",
    "   - **Optimization cycle** between optimize_prompt and evaluate_prompt\n",
    "\n",
    "   - Final **feedback loop** back to human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a5917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10eedefc0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add edges for the new flow\n",
    "workflow.add_edge(\"analyze_prompt\", \"human\")\n",
    "workflow.add_edge(\"human\", \"test_prompt\")\n",
    "workflow.add_edge(\"test_prompt\", \"optimize_prompt\")\n",
    "workflow.add_edge(\"optimize_prompt\", \"evaluate_prompt\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_prompt\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"CONTINUE\": \"human\",\n",
    "        \"FINISH\": END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5edaff",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "**4. Graph Compilation**:\n",
    "\n",
    "   - Sets analyze_prompt as **entry point**\n",
    "   \n",
    "   - Compiles with memory **checkpointing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38943703",
   "metadata": {
    "id": "38943703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workflow.set_entry_point(\"analyze_prompt\")\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f333c6",
   "metadata": {
    "id": "58f333c6"
   },
   "source": [
    "### **2.2 Visualize the Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd24831",
   "metadata": {
    "id": "acd24831",
    "outputId": "a8e89b3e-fc7d-4c66-bc83-267dd646d0a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd28d7f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c987b4d6",
   "metadata": {
    "id": "c987b4d6"
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "## **3. Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba8787",
   "metadata": {},
   "source": [
    "**Example #1: Execute the LangGraph Workflow for Prompt Optimization.**\n",
    "\n",
    "This code initializes and runs a LangGraph workflow to optimize an initial prompt through multiple iterations.\n",
    "The workflow streams events and updates for each step of the optimization process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a879d4",
   "metadata": {},
   "source": [
    "***Parameters:**\n",
    "\n",
    "- `recursion_limit (int)`: The maximum number of recursive iterations (default: 100).\n",
    "\n",
    "- `thread_id (str)`: A unique identifier for the workflow execution.\n",
    "\n",
    "- `initial_prompt (str)`: The starting prompt template to be optimized.\n",
    "\n",
    "- `stream_mode (str)`: The mode for streaming graph execution updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab064d1",
   "metadata": {},
   "source": [
    "**Run the Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a289d50",
   "metadata": {
    "id": "3a289d50",
    "outputId": "3d130baa-2bb5-4ec8-c336-001b5c822f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Here is the user's prompt ]\n",
      "What is the capital of Seoul?\n",
      "\n",
      "[ analyze_prompt ]\n",
      "\n",
      "Here is the feedback generated by AI: \n",
      "\n",
      "    (1) user's intent: seek information\n",
      "    (2) some improvement: clarify that Seoul is a city, not a country, and provide the correct capital for the country it's in\n",
      "    (3) revised prompt: \"Seoul is a city in South Korea. What is the capital of South Korea, and can you give an example of a famous landmark in that city?\"\n",
      "==============================  STEPS  ==============================\n",
      "[ Here is the proposed prompt ] \n",
      " \"Seoul is a city in South Korea. What is the capital of South Korea, and can you give an example of a famous landmark in that city?\"\n",
      "\n",
      "[ human ]\n",
      "\n",
      "\n",
      "==============================  STEPS  ==============================\n",
      "\n",
      "[ test_prompt ]\n",
      "\n",
      "Previous Prompt Response:\n",
      "Seoul is the capital city of South Korea, so it does not have a capital. However, if you're asking about the capital of the Seoul Special City, it is also Seoul. Is there anything else I can help you with?\n",
      "\n",
      "Revised Prompt Response:\n",
      "The capital of South Korea is Seoul, which you've already identified. A famous landmark in Seoul is the Gyeongbokgung Palace. This palace is the largest among the five royal palaces in Seoul and is a great example of traditional Korean architecture.\n",
      "\n",
      "Comparative Analysis:\n",
      "1. The key differences in the responses are as follows:\n",
      "   - The Previous Response clarifies that Seoul is the capital of South Korea and does not have its own capital, while the Revised Response directly states that Seoul is the capital of South Korea.\n",
      "   - The Previous Response does not provide any additional information about famous landmarks, whereas the Revised Response mentions the Gyeongbokgung Palace as a famous landmark in Seoul.\n",
      "2. The Revised Response is more direct, accurate, and informative than the Previous Response.\n",
      "3. The Revised Response is better because it directly answers the question, provides a well-known landmark in the capital city, and does so in a clear and concise manner.\n",
      "==============================  STEPS  ==============================\n",
      "\n",
      "[ optimize_prompt ]\n",
      "\n",
      "\"Seoul is a city in South Korea. What is the capital of South Korea, and can you give an example of a famous landmark in that city?\"\n",
      "==============================  STEPS  ==============================\n",
      "\n",
      "[ evaluate_prompt ]\n",
      "\n",
      "\n",
      "    - 2.1) 1\n",
      "    - 2.2) 0\n",
      "    - 2.3) 1\n",
      "    - 2.4) 1\n",
      "\n",
      "    The revised prompt is aligned with the user's intent, as it asks for the same information as the original prompt. However, it may not generate a better output since it is identical to the original prompt. The revised prompt is well-structured and of flexible length.\n",
      "\n",
      "    Total score: [3]\n",
      "==============================  STEPS  ==============================\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# Configure execution parameters\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=100, configurable={\"thread_id\": str(uuid.uuid4())}\n",
    ")\n",
    "\n",
    "initial_prompt = \"\"\"What is the capital of Seoul?\"\"\"\n",
    "\n",
    "\n",
    "# Initialize graph state with input prompt\n",
    "inputs = GraphState(prompt=[initial_prompt])\n",
    "\n",
    "# Execute graph and stream updates\n",
    "for event in graph.stream(inputs, config, stream_mode=\"updates\"):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n[ {key} ]\\n\")\n",
    "        if key == \"analyze_prompt\":\n",
    "            filtered_values = {k: v for k, v in value.items() if k != \"prompt\"}\n",
    "        elif key == \"human\":\n",
    "            filtered_values = {k: (\"\" if v[-1] in ['q', 'quit'] else v[-1]) for k, v in value.items()}\n",
    "        else:\n",
    "             filtered_values = value\n",
    "        for _, v in filtered_values.items():\n",
    "                if isinstance(v, list):\n",
    "                    print(f\"{v[-1]}\")\n",
    "                else:\n",
    "                     print(v)\n",
    "    print(\"===\" * 10, \" STEPS \", \"===\" * 10)\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ca2dd",
   "metadata": {
    "id": "e16ca2dd"
   },
   "source": [
    "**Check out the optimized prompt!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646f8bb",
   "metadata": {
    "id": "c646f8bb",
    "outputId": "1f7fa06e-904e-4a21-88b3-11ac6b6ab53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prompt Given: \n",
      "What is the capital of Seoul?\n",
      "============================================================\n",
      "Optimized Prompt: \n",
      "\"Seoul is a city in South Korea. What is the capital of South Korea, and can you give an example of a famous landmark in that city?\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config).values\n",
    "print(f\"Initial Prompt Given: \\n{snapshot['prompt'][0]}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"Optimized Prompt: \\n{snapshot['prompt'][-1]}\")\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd705464",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1dcd3",
   "metadata": {},
   "source": [
    "## **4. Full Code of Prompt Optimization with LangGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2496498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, TypedDict\n",
    "import operator\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END  \n",
    "\n",
    "# Retrieve the UPSTAGE_API_KEY variable from the IPython store\n",
    "%store -r UPSTAGE_API_KEY\n",
    "\n",
    "try:\n",
    "    if UPSTAGE_API_KEY:\n",
    "        print(\"Success!\")\n",
    "except NameError as ne:\n",
    "    print(f\"Since, {ne}\")\n",
    "    print(\"Please, insert your API key.\")\n",
    "    UPSTAGE_API_KEY = input(\"UPSTAGE_API_KEY =\")\n",
    "\n",
    "# Set your API key: \n",
    "# UPSTAGE_API_KEY = \" \" â†- Insert your API key here. \n",
    "\n",
    "# Initialization\n",
    "def get_llm(model: str =\"solar-pro\", temperature: float=0.0, **kwargs: any)-> ChatOpenAI:\n",
    "    return ChatOpenAI(\n",
    "        api_key=os.environ[\"UPSTAGE_API_KEY\"],\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "parser = RegexParser(\n",
    "    regex=r\"revised prompt:\\s*(.+)\",\n",
    "    output_keys=[\"revised_prompt\"]\n",
    ")\n",
    "solar = get_llm()\n",
    "\n",
    "# Set up the GraphState\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    A TypedDict class representing the state of the prompt optimization graph.\n",
    "\n",
    "    Attributes:\n",
    "        prompt (Annotated[list, operator.add]): List containing the prompts being optimized\n",
    "        ai_feedback (Annotated[list, operator.add]): List containing AI-generated feedback on prompts\n",
    "        human_feedback (Annotated[list, operator.add]): List containing human feedback on prompts\n",
    "    \"\"\"\n",
    "\n",
    "    prompt: Annotated[list, operator.add]\n",
    "    ai_feedback: Annotated[list, operator.add]\n",
    "    human_feedback: Annotated[list, operator.add]\n",
    "\n",
    "# 1st node: analyze_prompt\n",
    "def analyze_prompt(state: GraphState, llm: ChatOpenAI=solar) -> GraphState:\n",
    "    \"\"\"\n",
    "    Analyzes the given prompt and revise it for improvement.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state contains the prompt to analyze\n",
    "        llm (ChatOpenAI): Language model used to generate feedback and improvements\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Updated state with AI feedback and revised prompt\n",
    "    \"\"\"\n",
    "    latest_prompt = state[\"prompt\"][0]\n",
    "\n",
    "    print(\"[ Here is the user's prompt ]\")\n",
    "    print(latest_prompt)\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "    Your task is to analyze user's prompt. \n",
    "\n",
    "    1. Extract the user's intent. And write down a single word focused on 'action ascription'.\n",
    "    2. Check your output is aligned with the user's intent.   \n",
    "    3. Suggest me some improvements for the prompt. \n",
    "    4. Revise my prompt to ensure it includes two focal elements: examples and ample context within the prompt.\n",
    "    5. Your output should be within 4 sentences. Format: \n",
    "        (1) user's intent:\n",
    "        (2) some improvement:\n",
    "        (3) revised prompt: *don't answer to the user's prompt.\n",
    "        \n",
    "                                          \n",
    "    --------> \n",
    "    User's prompt: \n",
    "    {prompt}\n",
    "    --------> \n",
    "    \"\"\")\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    output = chain.invoke({\"prompt\": latest_prompt})\n",
    "    response = f\"Here is the feedback generated by AI: \\n{output}\"\n",
    "\n",
    "    parsed_response = parser.parse(output)\n",
    "    revised_prompt = parsed_response[\"revised_prompt\"]\n",
    "\n",
    "    return {\"prompt\": [revised_prompt],\n",
    "            \"ai_feedback\": [response]}\n",
    "\n",
    "# 2nd node: human\n",
    "def human_feedback(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Collects feedback from the user.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Update state with human feedback\n",
    "    \"\"\"\n",
    "    print(\"[ Here is the proposed prompt ] \\n\", state['prompt'][-1])\n",
    "    user_input = input(\"(Press 'q' or 'quit' to quit)\")\n",
    "\n",
    "    return {\"human_feedback\": [user_input]}\n",
    "\n",
    "# 3rd node: test_prompt\n",
    "def test_optimized_prompt(state: GraphState, llm: ChatOpenAI=get_llm(temperature=0.7)) -> GraphState:\n",
    "    \"\"\"\n",
    "    Tests both previous and current prompts, comparing their responses.\n",
    "    \n",
    "    Args:\n",
    "        state (GraphState): Current state containing both prompts\n",
    "        llm (ChatOpenAI): Language model( with temperature: 0.7 ) used to generate feedback\n",
    "        \n",
    "    Returns:\n",
    "        GraphState: Updated state with comparison of responses\n",
    "    \"\"\"\n",
    "    previous_prompt = state[\"prompt\"][-2]  # Get previous prompt\n",
    "    current_prompt = state[\"prompt\"][-1]  # Get latest prompt\n",
    "    \n",
    "    # Get responses for both prompts\n",
    "    previous_response = llm.invoke(previous_prompt)\n",
    "    revised_response = llm.invoke(current_prompt)\n",
    "    \n",
    "    # Compare the responses\n",
    "    comparison_prompt = f\"\"\"\n",
    "    Compare these two responses:\n",
    "    \n",
    "    PREVIOUS PROMPT: {previous_prompt}\n",
    "    PREVIOUS RESPONSE: {previous_response.content}\n",
    "    \n",
    "    REVISED PROMPT: {current_prompt}\n",
    "    REVISED RESPONSE: {revised_response.content}\n",
    "    \n",
    "    Please analyze:\n",
    "    1. Key differences in responses. \n",
    "    2. Summarize the differences within 1 sentence.  \n",
    "    3. tell me which one is better: Previous or Revised?  \n",
    "    \"\"\"\n",
    "\n",
    "    analysis = llm.invoke(comparison_prompt)\n",
    "    \n",
    "    return {\"ai_feedback\": [\n",
    "        f\"Previous Prompt Response:\\n{previous_response.content}\\n\\n\"\n",
    "        f\"Revised Prompt Response:\\n{revised_response.content}\\n\\n\"\n",
    "        f\"Comparative Analysis:\\n{analysis.content}\"\n",
    "    ]}\n",
    "\n",
    "# 4th node: optimize_prompt\n",
    "def optimize_prompt(state: GraphState, llm: ChatOpenAI=solar) -> GraphState:\n",
    "    \"\"\"\n",
    "    Optimizes the prompt based on your feedback and the user's feedback. \n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state contains the prompt, AI feedback(your feedback), and the user's feedback \n",
    "        llm (ChatOpenAI): Language model used to optimize prompt based on feedback\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Updated state with optimized prompt\n",
    "    \"\"\"\n",
    "    latest_prompt = state[\"prompt\"][-1]\n",
    "    latest_ai_feedback = state[\"ai_feedback\"][-1]\n",
    "    latest_human_feedback = state[\"human_feedback\"][-1]\n",
    "\n",
    "    if latest_human_feedback == \"q\" or latest_human_feedback == \"quit\":\n",
    "        latest_human_feedback = \"\"\n",
    "        return {\"prompt\": [latest_prompt]}\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Your task is to optimize the user's prompt. Follow these instructions: \n",
    "\n",
    "    Here is the prompt before improvement:\n",
    "    {prompt}\n",
    "\n",
    "    Here is previous feedback generated by AI:\n",
    "    {ai_feedback}\n",
    "\n",
    "    Here is Human's follow-up feedback:\n",
    "    {human_feedback}\n",
    "\n",
    "    Write down the improved prompt. Only present the revised prompt without any additional comments. \n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"prompt\": latest_prompt,\n",
    "            \"ai_feedback\": latest_ai_feedback,\n",
    "            \"human_feedback\": latest_human_feedback,\n",
    "        }\n",
    "    )\n",
    "    return {\"prompt\": [response]}\n",
    "\n",
    "# 5th node: evaluate_prompt\n",
    "def evaluate_prompt(state: GraphState, llm: ChatOpenAI=solar) -> GraphState:\n",
    "    \"\"\"\n",
    "    Evaluates the optimized prompt by comparing it to the previous prompt.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state contains the previous prompt and the optimized prompt\n",
    "        llm (ChatOpenAI): Language model used to evaluate the optimized prompt\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Updated state with evaluation feedback\n",
    "    \"\"\"\n",
    "    before_optimization_prompt = state[\"prompt\"][-2]\n",
    "    improved_prompt = state[\"prompt\"][-1]\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "    Now, let's evaluate the prompt. Follow these instructions: \n",
    "    - 1. Comparision : read two prompts carefully and think about the difference between them.  \n",
    "    previous prompt: {before_optimization_prompt}\n",
    "    revised prompt: {improved_prompt}\n",
    "\n",
    "    - 2. Scoring: Give a score between 0 and 1 for 4 criteria. Show your the total score at the end. \n",
    "    If yes add 1, else add 0.   \n",
    "      - 2.1) Is the revised prompt aligned with the user's intent? (yes or no)\n",
    "      - 2.2) Is the revised prompt able to generate a better output than the previous prompt? (yes or no)\n",
    "      - 2.3) Is the revised prompt well-structured? (yes or no)\n",
    "      - 2.4) Is the revised prompt of flexible length? (yes or no) \n",
    "    Sum up your score for each criterion: [ ]\n",
    "       \n",
    "    - 3. Writedown the justification for your score within 2 sentences. \n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"before_optimization_prompt\": before_optimization_prompt,\n",
    "            \"improved_prompt\": improved_prompt,\n",
    "        }\n",
    "    )\n",
    "    return {\"ai_feedback\": [response]}\n",
    "\n",
    "# An additional path: CONTINUE \n",
    "def should_continue(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether to continue the optimization loop based on the user's feedback.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Current state containing the user's feedback\n",
    "\n",
    "    Returns:\n",
    "        str: \"FINISH\" if the user wants to quit, \"CONTINUE\" otherwise\n",
    "    \"\"\"\n",
    "    latest_human_feedback = state[\"human_feedback\"][-1].strip()\n",
    "    if latest_human_feedback == \"q\" or latest_human_feedback == \"quit\":\n",
    "        return \"FINISH\"\n",
    "    else:\n",
    "        return \"CONTINUE\"\n",
    "    \n",
    "# Memory management\n",
    "memory = MemorySaver()\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Node configuration\n",
    "workflow.add_node(\"analyze_prompt\", analyze_prompt)\n",
    "workflow.add_node(\"human\", human_feedback)\n",
    "workflow.add_node(\"test_prompt\", test_optimized_prompt)\n",
    "workflow.add_node(\"optimize_prompt\", optimize_prompt)\n",
    "workflow.add_node(\"evaluate_prompt\", evaluate_prompt)\n",
    "\n",
    "# Add edges for the new flow\n",
    "workflow.add_edge(\"analyze_prompt\", \"human\")\n",
    "workflow.add_edge(\"human\", \"test_prompt\")\n",
    "workflow.add_edge(\"test_prompt\", \"optimize_prompt\")\n",
    "workflow.add_edge(\"optimize_prompt\", \"evaluate_prompt\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_prompt\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"CONTINUE\": \"human\",\n",
    "        \"FINISH\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Graph compilation\n",
    "workflow.set_entry_point(\"analyze_prompt\")\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ddfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# Configure execution parameters\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=100, configurable={\"thread_id\": str(uuid.uuid4())}\n",
    ")\n",
    "\n",
    "initial_prompt = \"\"\"What is the capital of Seoul?\"\"\"\n",
    "\n",
    "\n",
    "# Initialize graph state with input prompt\n",
    "inputs = GraphState(prompt=[initial_prompt])\n",
    "\n",
    "# Execute graph and stream updates\n",
    "for event in graph.stream(inputs, config, stream_mode=\"updates\"):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n[ {key} ]\\n\")\n",
    "        if key == \"analyze_prompt\":\n",
    "            filtered_values = {k: v for k, v in value.items() if k != \"prompt\"}\n",
    "        elif key == \"human\":\n",
    "            filtered_values = {k: (\"\" if v[-1] in ['q', 'quit'] else v[-1]) for k, v in value.items()}\n",
    "        else:\n",
    "             filtered_values = value\n",
    "        for _, v in filtered_values.items():\n",
    "                if isinstance(v, list):\n",
    "                    print(f\"{v[-1]}\")\n",
    "                else:\n",
    "                     print(v)\n",
    "    print(\"===\" * 10, \" STEPS \", \"===\" * 10)\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config).values\n",
    "print(f\"Initial Prompt Given: \\n{snapshot['prompt'][0]}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"Optimized Prompt: \\n{snapshot['prompt'][-1]}\")\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb6193f",
   "metadata": {},
   "source": [
    "\n",
    "We have covered the process of optimizing prompts using LangGraph. If you need to automate prompt optimization while working with Solar, consider leveraging LangGraph as introduced in this appendix.\n",
    "\n",
    "*The source code used in this appendix was provided by Teddy Lee.*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
